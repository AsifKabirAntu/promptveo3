import { execSync } from 'child_process'
import fs from 'fs'
import path from 'path'

interface VisualDetectorConfig {
  inputDir: string
  outputDir: string
  tempDir: string
  brandText: string
}

class VisualWatermarkDetector {
  private config: VisualDetectorConfig

  constructor() {
    this.config = {
      inputDir: path.join(process.cwd(), 'data', 'ulazai-videos'),
      outputDir: path.join(process.cwd(), 'data', 'promptveo3-visual-ai'),
      tempDir: path.join(process.cwd(), 'temp', 'visual-detection'),
      brandText: 'promptveo3.com'
    }
  }

  private ensureDirectories(): void {
    if (!fs.existsSync(this.config.outputDir)) {
      fs.mkdirSync(this.config.outputDir, { recursive: true })
    }
    if (!fs.existsSync(this.config.tempDir)) {
      fs.mkdirSync(this.config.tempDir, { recursive: true })
    }
  }

  private async extractFrameForAnalysis(videoPath: string): Promise<string> {
    const framePath = path.join(this.config.tempDir, 'analysis_frame.png')
    
    try {
      // Extract a frame from middle of video
      execSync(`ffmpeg -y -i "${videoPath}" -ss 2 -vframes 1 "${framePath}"`, { 
        stdio: 'pipe' 
      })
      return framePath
    } catch (error) {
      // Fallback to first frame
      execSync(`ffmpeg -y -i "${videoPath}" -vframes 1 "${framePath}"`, { 
        stdio: 'pipe' 
      })
      return framePath
    }
  }

  private async analyzeImageForTextRegions(framePath: string): Promise<Array<{x: number, y: number, width: number, height: number, desc: string}>> {
    // Get image dimensions
    const dimensionsOutput = execSync(`ffprobe -v quiet -print_format json -show_streams "${framePath}"`, { encoding: 'utf8' })
    const dimensions = JSON.parse(dimensionsOutput)
    const stream = dimensions.streams[0]
    const width = stream.width
    const height = stream.height

    console.log(`üìê Analyzing frame: ${width}x${height} (${height > width ? '9:16 vertical' : '16:9 horizontal'})`)

    // Create a comprehensive grid to analyze for text-like regions
    const regions = []
    const isVertical = height > width
    const regionSize = isVertical ? { w: 140, h: 35 } : { w: 150, h: 40 }
    
    if (isVertical) {
      // For vertical videos - analyze key positions where watermarks typically appear
      regions.push(
        // Bottom corners (most common)
        { x: 10, y: height - 60, width: regionSize.w, height: regionSize.h, desc: 'bottom-left' },
        { x: width - regionSize.w - 10, y: height - 60, width: regionSize.w, height: regionSize.h, desc: 'bottom-right' },
        
        // Mid-screen positions
        { x: 10, y: height * 0.8, width: regionSize.w, height: regionSize.h, desc: 'mid-left' },
        { x: width - regionSize.w - 10, y: height * 0.8, width: regionSize.w, height: regionSize.h, desc: 'mid-right' },
        
        // Center-bottom
        { x: (width - regionSize.w) / 2, y: height - 50, width: regionSize.w, height: regionSize.h, desc: 'bottom-center' },
        
        // Top positions (less likely)
        { x: 10, y: 10, width: regionSize.w, height: regionSize.h, desc: 'top-left' },
        { x: width - regionSize.w - 10, y: 10, width: regionSize.w, height: regionSize.h, desc: 'top-right' }
      )
    } else {
      // For horizontal videos
      regions.push(
        // Bottom corners
        { x: 10, y: height - 50, width: regionSize.w, height: regionSize.h, desc: 'bottom-left' },
        { x: width - regionSize.w - 10, y: height - 50, width: regionSize.w, height: regionSize.h, desc: 'bottom-right' },
        
        // Bottom center
        { x: (width - regionSize.w) / 2, y: height - 50, width: regionSize.w, height: regionSize.h, desc: 'bottom-center' },
        
        // Top corners
        { x: 10, y: 10, width: regionSize.w, height: regionSize.h, desc: 'top-left' },
        { x: width - regionSize.w - 10, y: 10, width: regionSize.w, height: regionSize.h, desc: 'top-right' }
      )
    }

    // Filter valid regions
    return regions.filter(region => 
      region.x >= 0 && 
      region.y >= 0 && 
      region.x + region.width <= width && 
      region.y + region.height <= height
    )
  }

  private async analyzeRegionForWatermark(framePath: string, region: any): Promise<number> {
    try {
      const regionPath = path.join(this.config.tempDir, `region_${region.desc}.png`)
      
      // Extract the specific region
      execSync(`ffmpeg -y -i "${framePath}" -vf "crop=${region.width}:${region.height}:${region.x}:${region.y}" "${regionPath}"`, { 
        stdio: 'pipe' 
      })

      // Enhance the region for better analysis
      const enhancedPath = path.join(this.config.tempDir, `enhanced_${region.desc}.png`)
      execSync(`ffmpeg -y -i "${regionPath}" -vf "scale=iw*4:ih*4,eq=contrast=2:brightness=0.1,unsharp=5:5:2.0" "${enhancedPath}"`, { 
        stdio: 'pipe' 
      })

      // Create a binary/threshold version to detect text-like patterns
      const binaryPath = path.join(this.config.tempDir, `binary_${region.desc}.png`)
      execSync(`ffmpeg -y -i "${enhancedPath}" -vf "eq=contrast=3:brightness=-0.2,threshold" "${binaryPath}"`, { 
        stdio: 'pipe' 
      })

      // Analyze the binary image for text-like characteristics
      // This is a simple heuristic - in production you'd use proper OCR/ML
      let confidence = 0.3 // Base confidence
      
      // Check file sizes as a proxy for text content
      const originalSize = fs.statSync(regionPath).size
      const enhancedSize = fs.statSync(enhancedPath).size
      const binarySize = fs.statSync(binaryPath).size
      
      // Text regions typically have specific characteristics in binary images
      const sizeRatio = binarySize / enhancedSize
      if (sizeRatio > 0.1 && sizeRatio < 0.8) {
        confidence += 0.3 // Boost for text-like compression characteristics
      }
      
      // Boost based on typical watermark positions
      if (region.desc.includes('bottom')) {
        confidence += 0.4 // Bottom regions are more likely
      }
      if (region.desc.includes('left')) {
        confidence += 0.1 // Slight preference for left (but not too strong)
      }
      if (region.desc.includes('right')) {
        confidence += 0.1 // Slight preference for right (but not too strong)
      }
      
      // Additional visual analysis could go here
      // For now, we'll use these heuristics
      
      // Clean up temp files
      if (fs.existsSync(regionPath)) fs.unlinkSync(regionPath)
      if (fs.existsSync(enhancedPath)) fs.unlinkSync(enhancedPath)
      if (fs.existsSync(binaryPath)) fs.unlinkSync(binaryPath)
      
      return Math.min(confidence, 1.0)
      
    } catch (error) {
      console.log(`‚ö†Ô∏è  Error analyzing region ${region.desc}:`, error)
      return 0.1
    }
  }

  private async detectWatermarkLocation(videoPath: string): Promise<{x: number, y: number, width: number, height: number, desc: string} | null> {
    console.log('üîç Visual analysis for watermark detection...')
    
    // Extract frame for analysis
    const framePath = await this.extractFrameForAnalysis(videoPath)
    
    // Get regions to analyze
    const regions = await this.analyzeImageForTextRegions(framePath)
    
    console.log(`üéØ Analyzing ${regions.length} potential regions...`)
    
    let bestRegion = null
    let bestScore = 0
    const results: any[] = []
    
    // Analyze each region
    for (const region of regions) {
      const score = await this.analyzeRegionForWatermark(framePath, region)
      results.push({ ...region, score })
      
      console.log(`üìä ${region.desc}: ${score.toFixed(2)}`)
      
      if (score > bestScore) {
        bestScore = score
        bestRegion = region
      }
    }
    
    // Clean up analysis frame
    if (fs.existsSync(framePath)) {
      fs.unlinkSync(framePath)
    }
    
    if (bestRegion && bestScore > 0.5) {
      console.log(`‚úÖ Detected watermark: ${bestRegion.desc} (confidence: ${bestScore.toFixed(2)})`)
      return bestRegion
    }
    
    console.log('‚ùå No high-confidence watermark detected')
    return null
  }

  async processVideo(inputPath: string, outputPath: string): Promise<boolean> {
    try {
      console.log(`üé¨ Processing: ${path.basename(inputPath)}`)
      
      // Detect watermark location
      const watermarkLocation = await this.detectWatermarkLocation(inputPath)
      
      if (!watermarkLocation) {
        console.log('‚ö†Ô∏è  Using intelligent fallback based on video type')
        
        // Smart fallback
        const dimensionsOutput = execSync(`ffprobe -v quiet -print_format json -show_streams "${inputPath}"`, { encoding: 'utf8' })
        const dimensions = JSON.parse(dimensionsOutput)
        const stream = dimensions.streams.find((s: any) => s.codec_type === 'video')
        const isVertical = stream.height > stream.width
        
        let fallbackCmd
        if (isVertical) {
          // For vertical videos, slight preference for bottom-left but try both
          fallbackCmd = `ffmpeg -y -i "${inputPath}" \\
            -vf "delogo=x=10:y=h-60:w=140:h=35:show=0,delogo=x=w-150:y=h-60:w=140:h=35:show=0, \\
                 drawtext=text='${this.config.brandText}':fontfile=/System/Library/Fonts/Arial.ttf:fontsize=14:fontcolor=white:x=15:y=h-55:box=1:boxcolor=0x2563eb@0.95:boxborderw=5" \\
            -c:a copy "${outputPath}"`
        } else {
          fallbackCmd = `ffmpeg -y -i "${inputPath}" \\
            -vf "delogo=x=10:y=h-50:w=150:h=40:show=0, \\
                 drawtext=text='${this.config.brandText}':fontfile=/System/Library/Fonts/Arial.ttf:fontsize=16:fontcolor=white:x=15:y=h-45:box=1:boxcolor=0x2563eb@0.95:boxborderw=5" \\
            -c:a copy "${outputPath}"`
        }
        
        execSync(fallbackCmd, { stdio: 'pipe' })
        return true
      }
      
      // Use detected location for precise removal and branding
      const removeX = watermarkLocation.x
      const removeY = watermarkLocation.y
      const removeW = watermarkLocation.width
      const removeH = watermarkLocation.height
      
      // Position our brand in detected location
      const brandX = removeX + 5
      const brandY = removeY + 5
      const fontSize = watermarkLocation.desc.includes('vertical') ? 14 : 16
      
      const visualCmd = `ffmpeg -y -i "${inputPath}" \\
        -vf "delogo=x=${removeX}:y=${removeY}:w=${removeW}:h=${removeH}:show=0, \\
             drawtext=text='${this.config.brandText}':fontfile=/System/Library/Fonts/Arial.ttf:fontsize=${fontSize}:fontcolor=white:x=${brandX}:y=${brandY}:box=1:boxcolor=0x2563eb@0.95:boxborderw=5" \\
        -c:a copy "${outputPath}"`
      
      console.log(`üé® Applying visual AI watermark replacement...`)
      execSync(visualCmd, { stdio: 'pipe' })
      
      return true
      
    } catch (error) {
      console.error(`‚ùå Error processing ${path.basename(inputPath)}:`, error)
      return false
    }
  }

  async processVideos(limit: number = 3): Promise<void> {
    console.log('üëÅÔ∏è  Visual AI Watermark Detection & Replacement')
    console.log('==============================================')
    console.log(`üìÇ Input: ${this.config.inputDir}`)
    console.log(`üìÇ Output: ${this.config.outputDir}`)
    console.log(`üè∑Ô∏è  Brand: ${this.config.brandText}`)
    console.log('')

    this.ensureDirectories()

    const videoFiles = fs.readdirSync(this.config.inputDir)
      .filter(file => file.endsWith('.mp4') || file.endsWith('.mov'))
      .slice(0, limit)

    console.log(`üé¨ Found ${videoFiles.length} videos to process`)

    let totalProcessed = 0
    let totalSuccessful = 0
    
    for (const videoFile of videoFiles) {
      const inputPath = path.join(this.config.inputDir, videoFile)
      const outputFileName = videoFile.replace(/\.(mp4|mov)$/, '-visual-ai.mp4')
      const outputPath = path.join(this.config.outputDir, outputFileName)
      
      if (fs.existsSync(outputPath)) {
        console.log(`‚è≠Ô∏è  Skipping ${videoFile} (already processed)`)
        continue
      }
      
      totalProcessed++
      console.log(`\nüé¨ Processing ${totalProcessed}/${videoFiles.length}: ${videoFile}`)
      console.log('')
      
      const success = await this.processVideo(inputPath, outputPath)
      
      if (success) {
        totalSuccessful++
        const stats = fs.statSync(outputPath)
        const sizeMB = (stats.size / (1024 * 1024)).toFixed(1)
        console.log(`‚úÖ Visual AI complete: ${outputFileName} (${sizeMB}MB)`)
      }
      console.log('')
    }
    
    console.log('\nüëÅÔ∏è  Visual AI Processing Complete!')
    console.log('==================================')
    console.log(`üìä Total processed: ${totalProcessed}`)
    console.log(`‚úÖ Successful: ${totalSuccessful}`)
    console.log(`‚ùå Failed: ${totalProcessed - totalSuccessful}`)
    console.log('')
    console.log('üéØ Visual AI Features:')
    console.log('   ‚Ä¢ Enhanced image analysis for text detection')
    console.log('   ‚Ä¢ Binary/threshold processing for better accuracy')
    console.log('   ‚Ä¢ Adaptive positioning based on detected content')
    console.log('   ‚Ä¢ Multi-position fallback for edge cases')
  }
}

// CLI interface
async function main() {
  const limit = process.argv[2] ? parseInt(process.argv[2]) : 3
  const detector = new VisualWatermarkDetector()
  await detector.processVideos(limit)
}

if (require.main === module) {
  main().catch(console.error)
}

export default VisualWatermarkDetector 